{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56de7685-b564-4320-896c-423f70da087f",
   "metadata": {},
   "source": [
    "# XNLI\n",
    "1. train set 下载地址: \n",
    "2. dev and test set 下载地址: https://dl.fbaipublicfiles.com/XNLI/XNLI-1.0.zip (`xnli.dev.tsv`, `xnli.test.tsv`)\n",
    "3. 这里我已经将数据集下载到本地（`ChineseBERT-Paddle/data/XNLI`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11464d29-1dd1-44e4-983a-923ec64aaf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data1/workspace/research/ChineseBERT-Paddle/Paddle_ChineseBert/PaddleNLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a72904-5913-46cc-845b-172bcde30a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "from paddlenlp.datasets import load_dataset\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f07a98-fe9a-42b1-b8c5-7b1869f2a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "def read_train_ds(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        # 跳过列名\n",
    "        head = None\n",
    "        for line in f:\n",
    "            data = line.strip().split('\\t', 2)\n",
    "            if not head:\n",
    "                head = data\n",
    "            else:\n",
    "                sentence1, sentence2, label = data\n",
    "                yield {\"sentence1\": sentence1, \"sentence2\": sentence2, \"label\": label}\n",
    "\n",
    "def read(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        # 跳过列名\n",
    "        head = None\n",
    "        for line in f:\n",
    "            data = line.strip().split('\\t')\n",
    "            if not head:\n",
    "                head = data\n",
    "            else:\n",
    "                lan = data[0]\n",
    "                label = data[1]\n",
    "                sentence1 = data[6]\n",
    "                sentence2 = data[7]     \n",
    "                if lan != 'zh':\n",
    "                    continue\n",
    "                else:\n",
    "                    yield {\"sentence1\": sentence1, \"sentence2\": sentence2, \"label\": label}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6c7cf6-9bd2-4e7c-9f0e-876c78925858",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_dataset(read_train_ds, data_path='./data/XNLI/xnli.train.tsv', lazy=False)\n",
    "dev_ds = load_dataset(read, data_path='./data/XNLI/xnli.dev.tsv', lazy=False)\n",
    "test_ds = load_dataset(read, data_path='./data/XNLI/xnli.test.tsv', lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d62b709a-da33-48fc-87c8-627eb167a4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'sentence1': '从 概念 上 看 , 奶油 收入 有 两 个 基本 方面 产品 和 地理 .',\n",
       "   'sentence2': '产品 和 地理 是 什么 使 奶油 抹 霜 工作 .',\n",
       "   'label': 'neutral'},\n",
       "  {'sentence1': '你 知道 在 这个 季节 , 我 猜 在 你 的 水平 你 把 他们 丢到 下 一个 水平 , 如果 他们 决定 召回 的 家长 队 , 勇士 队 决定 打电话 召回 一个 家伙 从 三 个 a , 然后 一个 双人 上 去. 取代 他 和 一个 男人 去 取代 他',\n",
       "   'sentence2': '如果 人们 记得 的 话 , 你 就 会 把 事情 弄 丢 了 .',\n",
       "   'label': 'entailment'},\n",
       "  {'sentence1': '我们 的 一个 号码 会 非常 详细 地 执行 你 的 指示',\n",
       "   'sentence2': '我 团队 的 一个 成员 将 非常 精确 地 执行 你 的 命令',\n",
       "   'label': 'entailment'}],\n",
       " [{'sentence1': '他说，妈妈，我回来了。',\n",
       "   'sentence2': '校车把他放下后，他立即给他妈妈打了电话。',\n",
       "   'label': 'neutral'},\n",
       "  {'sentence1': '他说，妈妈，我回来了。',\n",
       "   'sentence2': '他没说一句话。',\n",
       "   'label': 'contradiction'},\n",
       "  {'sentence1': '他说，妈妈，我回来了。',\n",
       "   'sentence2': '他告诉他的妈妈他已经回到家了。',\n",
       "   'label': 'entailment'}],\n",
       " [{'sentence1': '嗯，我根本没想过，但是我很沮丧，最后我又和他说话了。',\n",
       "   'sentence2': '我还没有和他再次谈论。',\n",
       "   'label': 'contradiction'},\n",
       "  {'sentence1': '嗯，我根本没想过，但是我很沮丧，最后我又和他说话了。',\n",
       "   'sentence2': '我非常沮丧，我刚刚开始跟他说话。',\n",
       "   'label': 'entailment'},\n",
       "  {'sentence1': '嗯，我根本没想过，但是我很沮丧，最后我又和他说话了。',\n",
       "   'sentence2': '我们谈得很好。',\n",
       "   'label': 'neutral'}])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:3], dev_ds[:3], test_ds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e690eb6e-e870-4cfe-a19f-abb067cc0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example(example, tokenizer, max_seq_length=512, is_test=False):\n",
    "    \n",
    "    # 【FOCUS】 --> https://github.com/ShannonAI/ChineseBert/blob/main/datasets/xnli_dataset.py\n",
    "    label_map = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2, \"contradictory\": 2}\n",
    "    first, second, third = example['sentence1'], example['sentence2'], example['label']\n",
    "\n",
    "    first_input_tokens = tokenizer.tokenize(first)\n",
    "    first_pinyin_tokens = tokenizer.convert_sentence_to_pinyin_ids(first, with_specail_token=False)\n",
    "    \n",
    "    second_input_tokens = tokenizer.tokenize(second)\n",
    "    second_pinyin_tokens = tokenizer.convert_sentence_to_pinyin_ids(second, with_specail_token=False)\n",
    "\n",
    "    label = np.array([label_map[third]], dtype=\"int64\")\n",
    "    \n",
    "    # convert sentence to id\n",
    "    bert_tokens = tokenizer.convert_tokens_to_ids(first_input_tokens) + [102] + tokenizer.convert_tokens_to_ids(second_input_tokens)\n",
    "    pinyin_tokens = first_pinyin_tokens + [[0] * 8] + second_pinyin_tokens\n",
    "    if len(bert_tokens) > max_seq_length - 2:\n",
    "        bert_tokens = bert_tokens[:max_seq_length - 2]\n",
    "        pinyin_tokens = pinyin_tokens[:max_seq_length - 2]\n",
    "    # assert\n",
    "    assert len(bert_tokens) <= max_seq_length\n",
    "    assert len(bert_tokens) == len(pinyin_tokens)\n",
    "\n",
    "    input_ids = [101] + bert_tokens + [102]\n",
    "    pinyin_ids = [[0] * 8] + pinyin_tokens + [[0] * 8]\n",
    "    \n",
    "    input_ids = np.array(input_ids)\n",
    "    pinyin_ids = np.array(pinyin_ids)\n",
    "    \n",
    "\n",
    "    return input_ids, pinyin_ids, label\n",
    "\n",
    "def create_dataloader(dataset,\n",
    "                      mode='train',\n",
    "                      batch_size=1,\n",
    "                      batchify_fn=None,\n",
    "                      trans_fn=None):\n",
    "    if trans_fn:\n",
    "        dataset = dataset.map(trans_fn)\n",
    "\n",
    "    shuffle = True if mode == 'train' else False\n",
    "    # shuffle = False\n",
    "    if mode == 'train':\n",
    "        batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        batch_sampler = paddle.io.BatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return paddle.io.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"sets random seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    paddle.seed(seed)\n",
    "\n",
    "\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    \"\"\"\n",
    "    Given a dataset, it evals model and computes the metric.\n",
    "    Args:\n",
    "        model(obj:`paddle.nn.Layer`): A model to classify texts.\n",
    "        data_loader(obj:`paddle.io.DataLoader`): The dataset loader which generates batches.\n",
    "        criterion(obj:`paddle.nn.Layer`): It can compute the loss.\n",
    "        metric(obj:`paddle.metric.Metric`): The evaluation metric.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for batch in data_loader:\n",
    "        input_ids, pinyin_ids, labels = batch\n",
    "        logits = model(input_ids, pinyin_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "        accu = metric.accumulate()\n",
    "    print(\"eval loss: %.5f, accu: %.5f\" % (np.mean(losses), accu))\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "\n",
    "\n",
    "def do_train(model, tokenizer):\n",
    "    paddle.set_device(args.device)\n",
    "    rank = paddle.distributed.get_rank()\n",
    "    if paddle.distributed.get_world_size() > 1:\n",
    "        paddle.distributed.init_parallel_env()\n",
    "\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    trans_func = partial(\n",
    "        convert_example,\n",
    "        tokenizer=tokenizer)\n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment\n",
    "        Stack(dtype=\"int64\")  # label\n",
    "    ): [data for data in fn(samples)]\n",
    "    train_data_loader = create_dataloader(\n",
    "        train_ds,\n",
    "        mode='train',\n",
    "        batch_size=args.batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)\n",
    "    dev_data_loader = create_dataloader(\n",
    "        dev_ds,\n",
    "        mode='dev',\n",
    "        batch_size=args.batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)\n",
    "    \n",
    "    test_data_loader = create_dataloader(\n",
    "        test_ds,\n",
    "        mode='test',\n",
    "        batch_size=args.batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)\n",
    "\n",
    "    if args.init_from_ckpt and os.path.isfile(args.init_from_ckpt):\n",
    "        state_dict = paddle.load(args.init_from_ckpt)\n",
    "        model.set_dict(state_dict)\n",
    "    model = paddle.DataParallel(model)\n",
    "\n",
    "    num_training_steps = len(train_data_loader) * args.epochs\n",
    "\n",
    "    lr_scheduler = LinearDecayWithWarmup(args.learning_rate, num_training_steps,\n",
    "                                         args.warmup_proportion)\n",
    "\n",
    "    # Generate parameter names needed to perform weight decay.\n",
    "    # All bias and LayerNorm parameters are excluded.\n",
    "    decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "    optimizer = paddle.optimizer.AdamW(\n",
    "        learning_rate=lr_scheduler,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=args.weight_decay,\n",
    "        apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "    criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "    metric = paddle.metric.Accuracy()\n",
    "\n",
    "    global_step = 0\n",
    "    tic_train = time.time()\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        for step, batch in enumerate(train_data_loader, start=1):\n",
    "            input_ids, pinyin_ids, labels = batch\n",
    "            logits = model(input_ids, pinyin_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "            probs = F.softmax(logits, axis=1)\n",
    "            correct = metric.compute(probs, labels)\n",
    "            metric.update(correct)\n",
    "            acc = metric.accumulate()\n",
    "\n",
    "            global_step += 1\n",
    "            if global_step % 10 == 0 and rank == 0:\n",
    "                print(\n",
    "                    \"global step %d, epoch: %d, batch: %d, loss: %.5f, accu: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, step, loss, acc,\n",
    "                       10 / (time.time() - tic_train)))\n",
    "                tic_train = time.time()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "            if global_step % 100 == 0 and rank == 0:\n",
    "                save_dir = os.path.join(args.save_dir, \"model_%d\" % global_step)\n",
    "                if not os.path.exists(save_dir):\n",
    "                    os.makedirs(save_dir)\n",
    "                print(\"dev eval:\")\n",
    "                evaluate(model, criterion, metric, dev_data_loader)\n",
    "                print(\"test eval:\")\n",
    "                evaluate(model, criterion, metric, test_data_loader)\n",
    "                # model._layers.save_pretrained(save_dir)\n",
    "                # tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e47cb9d-51c4-4581-9b24-efa8c08fe52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 18:16:56.745079 22892 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 6.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0916 18:16:56.749233 22892 device_context.cc:422] device: 0, cuDNN Version: 8.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.29300141,  0.06154867, -0.04159497, -0.24178788],\n",
      "        [ 0.12031405,  0.07091312,  0.00587054, -0.19262496]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.13836509, -0.04072359,  0.08384413, -0.26441869],\n",
      "        [ 0.21721396, -0.22747000,  0.03117523, -0.11488929]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.17472669, -0.12867226,  0.17266887, -0.13069257],\n",
      "        [ 0.49496806, -0.18507436, -0.00395256, -0.10577026]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.29058242, -0.31666705, -0.13665821, -0.17656021],\n",
      "        [ 0.22873819, -0.01709885, -0.05359051, -0.17607048]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.09601748,  0.24593727, -0.44436669, -0.41083151],\n",
      "        [ 0.30488005, -0.02186015, -0.05324380, -0.27282810]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.30608553, -0.03177077,  0.00231445, -0.07198434],\n",
      "        [ 0.17521787,  0.11613576, -0.57048762, -0.11131112]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.31076479, -0.24805833,  0.01727349, -0.27077791],\n",
      "        [ 0.25606063, -0.16355911,  0.01351763, -0.13861167]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.29144001, -0.04585474, -0.01232535, -0.13411540],\n",
      "        [ 0.44515875, -0.10552127,  0.09085938,  0.07902686]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.45729184,  0.01031128,  0.10699579, -0.10315689],\n",
      "        [ 0.22295353,  0.06486437, -0.05928890, -0.27576044]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.23400515, -0.11358163, -0.02604326, -0.18783024],\n",
      "        [ 0.19460678, -0.19587745, -0.15924951, -0.28431278]])\n",
      "global step 10, epoch: 1, batch: 10, loss: 1.29383, accu: 0.40000, speed: 2.99 step/s\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.12513763, -0.02999254, -0.52945483, -0.09381285],\n",
      "        [ 0.25650454, -0.15599735, -0.05114197, -0.13960990]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.15547767, -0.18529871, -0.13969339, -0.28762534],\n",
      "        [ 0.35271892,  0.06560586, -0.17317206, -0.13780111]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.14164296, -0.16672225, -0.08240838, -0.18614934],\n",
      "        [ 0.26988167, -0.12691544, -0.06552953, -0.44530249]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.27347702,  0.04138672,  0.07086872, -0.09831592],\n",
      "        [ 0.40654999,  0.08366564, -0.01675166, -0.23408428]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.03567407, -0.00018219, -0.28655994, -0.15631904],\n",
      "        [ 0.35750690, -0.23054799,  0.11309838, -0.17812933]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.29461268, -0.06420832, -0.22584245, -0.07955507],\n",
      "        [ 0.13480544, -0.12103069,  0.05303604, -0.12513176]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.16839665, -0.11647579,  0.08690137, -0.16128597],\n",
      "        [ 0.25558269,  0.08523929, -0.07681965, -0.29329824]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.27164063,  0.10818577, -0.12573113, -0.01071218],\n",
      "        [ 0.14652802,  0.01863691, -0.41651511, -0.32823497]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.21484753, -0.06560732, -0.16971081, -0.07314253],\n",
      "        [ 0.28160635, -0.02038371, -0.07338496, -0.03508919]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.25677061, -0.25484285, -0.17294930, -0.27532306],\n",
      "        [ 0.25213173, -0.03362998, -0.11506861, -0.14810382]])\n",
      "global step 20, epoch: 1, batch: 20, loss: 1.34528, accu: 0.40000, speed: 4.57 step/s\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.22279523, -0.06221831, -0.00785970, -0.31648511],\n",
      "        [ 0.19748712, -0.05449688, -0.30493873, -0.36643675]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.30212331, -0.13048229,  0.02117700, -0.26117066],\n",
      "        [ 0.40605694,  0.04345662,  0.12980156, -0.26053658]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.13933332, -0.22816911,  0.15391046, -0.25651276],\n",
      "        [ 0.41504323, -0.21487525,  0.01507087, -0.13118480]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.16059113, -0.12771124, -0.01956500, -0.08883918],\n",
      "        [ 0.23899174, -0.07462315, -0.03403706, -0.49459362]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.20209283, -0.06101198,  0.05291061, -0.21590389],\n",
      "        [ 0.24271214, -0.15288688, -0.35714579, -0.36107200]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[-0.16206390,  0.34205660, -0.33252555, -0.34080085],\n",
      "        [ 0.31023675, -0.07368986, -0.13787957, -0.23171270]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.26219621, -0.14076647, -0.02178573, -0.24684684],\n",
      "        [ 0.36033276, -0.15759028,  0.06304581, -0.25231013]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.27883056, -0.00372107,  0.07661727, -0.14774679],\n",
      "        [ 0.15439624, -0.01787697,  0.13139117, -0.10410895]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.43447745, -0.27690387, -0.07989825, -0.18029632],\n",
      "        [ 0.24236320, -0.13548367,  0.05616163, -0.19659574]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.24407928,  0.01536314,  0.06095250, -0.11770954],\n",
      "        [ 0.42536050, -0.11995453, -0.00188968, -0.16094095]])\n",
      "global step 30, epoch: 1, batch: 30, loss: 1.47763, accu: 0.31667, speed: 4.60 step/s\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.25796795, -0.14688423, -0.00886306, -0.23311548],\n",
      "        [ 0.46350926,  0.02230189, -0.09449533, -0.13781156]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.14147845, -0.05051629,  0.06021068, -0.19243877],\n",
      "        [ 0.27011111,  0.09140206, -0.11793710, -0.33658138]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.41198191, -0.05855767, -0.07437623, -0.13335492],\n",
      "        [ 0.31085956,  0.01152562, -0.01067973, -0.19546187]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.31892616, -0.10598385, -0.22389317, -0.13505790],\n",
      "        [ 0.26892531, -0.11611363, -0.18680179, -0.20125091]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[-0.10622286,  0.14556085, -0.70756280, -0.31322011],\n",
      "        [ 0.41823488,  0.06532970, -0.00639402, -0.15631260]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.24991758, -0.08504787, -0.01242318, -0.04987027],\n",
      "        [ 0.17801946, -0.04368751, -0.15899512, -0.21340448]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[-0.13400929,  0.41017950, -0.26466843, -0.36267304],\n",
      "        [ 0.41475630, -0.18034002,  0.12223227, -0.19042362]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.08799147, -0.21747054, -0.23142928, -0.12399495],\n",
      "        [ 0.28646007, -0.03558823, -0.06119357, -0.05092000]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.08709119, -0.12621385,  0.03333789, -0.07975630],\n",
      "        [ 0.37461644,  0.23713456, -0.48416641, -0.34757930]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.27269670, -0.14782883,  0.11220449, -0.29031429],\n",
      "        [ 0.29209861, -0.08457381, -0.02459542, -0.13962404]])\n",
      "global step 40, epoch: 1, batch: 40, loss: 1.33226, accu: 0.37500, speed: 4.59 step/s\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.10825311,  0.03446662,  0.03773105, -0.18354659],\n",
      "        [ 0.25378740, -0.10469876, -0.23289029, -0.21507631]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.40910056,  0.00074750,  0.02781943, -0.36744469],\n",
      "        [ 0.30842862, -0.01375709, -0.10359758, -0.24332273]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.10525313, -0.03845979,  0.01939573, -0.29502234],\n",
      "        [ 0.17977141, -0.06750927, -0.10204069, -0.10413742]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.18259625,  0.00230372, -0.20748067, -0.16243522],\n",
      "        [ 0.29744646, -0.09274239,  0.01501635, -0.11830617]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.24269333, -0.12049842, -0.15717860, -0.00417255],\n",
      "        [ 0.38363028,  0.08838286, -0.16539960, -0.25785783]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.33297682,  0.00949233,  0.00172700, -0.14477862],\n",
      "        [ 0.26881978, -0.04346318,  0.11118001, -0.14291604]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.28961512, -0.03471278, -0.08843853, -0.18261011],\n",
      "        [ 0.31088567,  0.04609501, -0.18431422, -0.16568322]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.39813310, -0.10086341,  0.07082799, -0.10970754],\n",
      "        [ 0.35751724,  0.01109508, -0.04841489, -0.08001541]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.25136507, -0.08184896,  0.16422042, -0.21094190],\n",
      "        [ 0.29750031, -0.13696383,  0.05340169, -0.37803388]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.25166798,  0.01537658, -0.05386959, -0.02655995],\n",
      "        [ 0.28404179, -0.12634651,  0.17648520, -0.18889168]])\n",
      "global step 50, epoch: 1, batch: 50, loss: 1.34553, accu: 0.33000, speed: 4.59 step/s\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.38461876,  0.03211461, -0.10196282, -0.19402917],\n",
      "        [ 0.34029967, -0.08662480, -0.09770522, -0.06395341]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.20088813,  0.00545643, -0.07758216, -0.27427071],\n",
      "        [ 0.30550653, -0.02415195,  0.02003994, -0.26260933]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.22307357, -0.30461815, -0.12015880, -0.34598717],\n",
      "        [ 0.19708072,  0.04482640, -0.14409606, -0.12432279]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.35338464, -0.19643316,  0.01380680, -0.31356594],\n",
      "        [ 0.34490287, -0.15358359, -0.01431209, -0.16493990]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.27499041, -0.06979078, -0.09217604, -0.03807313],\n",
      "        [ 0.19886330, -0.00419336, -0.36145085, -0.30774212]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.10250691, -0.01593759, -0.06213191, -0.10022142],\n",
      "        [ 0.35907254, -0.07939784,  0.03095153, -0.18538789]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.27040258, -0.14651133, -0.10812852, -0.14404920],\n",
      "        [ 0.17370047,  0.03417396,  0.04922228, -0.15129650]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.23558091,  0.01240474, -0.06751245, -0.21470116],\n",
      "        [ 0.21144341, -0.27712265,  0.06494230, -0.23965831]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.27158347,  0.03959334, -0.20897311, -0.21981230],\n",
      "        [ 0.39318097,  0.00630733, -0.17329797, -0.14596410]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.24402651, -0.07850335, -0.08409546, -0.30012661],\n",
      "        [ 0.26791793, -0.20899276, -0.08354244, -0.06120724]])\n",
      "global step 60, epoch: 1, batch: 60, loss: 1.27128, accu: 0.34167, speed: 4.52 step/s\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.25196251,  0.16545841, -0.12456580, -0.21543300],\n",
      "        [ 0.33579180, -0.02046556, -0.05861261, -0.18587461]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.24334250, -0.09335594, -0.02722386, -0.26478714],\n",
      "        [ 0.12266669, -0.22160161, -0.01080600, -0.16980113]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.25169975, -0.07045806,  0.07208303, -0.18246348],\n",
      "        [ 0.38647249, -0.12825894,  0.10988528, -0.13269445]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.24259678,  0.09667799,  0.09064595, -0.09117460],\n",
      "        [ 0.26981625,  0.01886046,  0.01033423, -0.18515350]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.24667341, -0.22104235, -0.07009184, -0.06735726],\n",
      "        [ 0.36463225, -0.13146369, -0.16708006, -0.43216017]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.25663516, -0.19978106, -0.00972687, -0.22949380],\n",
      "        [ 0.36708191, -0.16617160, -0.25804114, -0.19763163]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.13374825, -0.05268399, -0.16293834, -0.09704242],\n",
      "        [ 0.20436011,  0.04643980,  0.04637196, -0.26123682]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.28812364, -0.16641223,  0.06977477, -0.03448980],\n",
      "        [ 0.29967004, -0.01384695,  0.11252304, -0.02053045]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.11311042,  0.01519479, -0.43854436, -0.37277853],\n",
      "        [ 0.13804708, -0.04420819, -0.07542602, -0.20725153]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.25018305, -0.05347080,  0.05894838, -0.08110768],\n",
      "        [ 0.30921754,  0.04216021, -0.00990904, -0.01859833]])\n",
      "global step 70, epoch: 1, batch: 70, loss: 1.17782, accu: 0.33571, speed: 4.50 step/s\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.24822703, -0.11151791,  0.05361502, -0.18373215],\n",
      "        [ 0.20731029,  0.05146385,  0.03201052, -0.16645241]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.25986904, -0.00810364, -0.58108544, -0.31155536],\n",
      "        [ 0.28002980, -0.09980842,  0.02625583, -0.20646073]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.36322245, -0.11175057, -0.13069662, -0.15220617],\n",
      "        [ 0.31861097, -0.17809421,  0.05954418, -0.21837869]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.32868302, -0.04895228, -0.04014152, -0.18296048],\n",
      "        [ 0.41995496,  0.01771815, -0.19315577, -0.16443059]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.11821520,  0.01103503, -0.27445188, -0.21264869],\n",
      "        [ 0.22456951,  0.09868889, -0.10244960, -0.13542613]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.49559903,  0.04571903,  0.05127047, -0.04670201],\n",
      "        [ 0.09530471, -0.12462544, -0.50035626, -0.32310319]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.19073325, -0.19153523, -0.02851145, -0.14736255],\n",
      "        [ 0.32836562, -0.01368456, -0.00959794, -0.15505697]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.41264275, -0.07779071, -0.11163676,  0.01683812],\n",
      "        [ 0.27183568, -0.07050859, -0.07725586, -0.32920787]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.20207916, -0.15190132,  0.10998932, -0.12449896],\n",
      "        [ 0.28709695,  0.01883764,  0.07944171, -0.27091318]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.29200342, -0.11524282, -0.04153834, -0.25319979],\n",
      "        [ 0.37610671, -0.11253969, -0.02677673, -0.18149284]])\n",
      "global step 80, epoch: 1, batch: 80, loss: 1.51524, accu: 0.33750, speed: 4.55 step/s\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.23018253, -0.11560989, -0.44821864, -0.27403790],\n",
      "        [ 0.19859867, -0.17126049,  0.01850340, -0.12702452]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[-0.03022082,  0.27017778, -0.29326975, -0.04629217],\n",
      "        [ 0.17857182, -0.06715592,  0.08413854, -0.29230937]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.11990347,  0.20489554, -0.41735253, -0.29787505],\n",
      "        [ 0.41674790, -0.06333688, -0.12107247, -0.11450710]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.39353558, -0.06316598, -0.06642100, -0.14370558],\n",
      "        [ 0.31521618, -0.10931838, -0.01283443, -0.19058736]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.35832715,  0.01158033, -0.09493779, -0.22113070],\n",
      "        [ 0.26093498, -0.03504346, -0.20222050, -0.19911085]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.13927014, -0.13351785, -0.06635587, -0.19250214],\n",
      "        [ 0.14353900, -0.09467448,  0.00122887, -0.35033095]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.22588661, -0.03172472, -0.10233524, -0.27347448],\n",
      "        [ 0.20106316,  0.08368950, -0.09068397, -0.14917578]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.08475973, -0.08533210, -0.04351510, -0.19324578],\n",
      "        [ 0.27639550, -0.11695117,  0.20004749, -0.21998259]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.38014686,  0.09380365,  0.16132025, -0.12810853],\n",
      "        [ 0.28833237, -0.10925001, -0.14854762, -0.20719326]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.31198207, -0.00232470, -0.05711616, -0.23503515],\n",
      "        [ 0.18949038,  0.01738810, -0.01837991, -0.17795043]])\n",
      "global step 90, epoch: 1, batch: 90, loss: 1.33790, accu: 0.35000, speed: 4.44 step/s\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.28130525, -0.16574872, -0.11315190, -0.13379078],\n",
      "        [ 0.31664237, -0.14541732,  0.03266127, -0.07166425]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.11982539, -0.08925708, -0.20223331, -0.23195066],\n",
      "        [ 0.32254487, -0.09125277,  0.05327783, -0.17704435]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.25251198,  0.03949460, -0.09718070, -0.31783742],\n",
      "        [ 0.30218965, -0.28460553, -0.02353812,  0.00569170]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.32611099, -0.10512237, -0.03290021, -0.32433447],\n",
      "        [ 0.23098092, -0.08156129,  0.02177841, -0.21908368]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.12234608, -0.02675652, -0.50773489, -0.37355858],\n",
      "        [ 0.35704702,  0.08961032,  0.01127432, -0.16645366]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.15778497, -0.00803347, -0.16917171, -0.24767971],\n",
      "        [ 0.23349780, -0.12726060, -0.12542750, -0.18534005]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.38860616, -0.19147164, -0.05727391, -0.09331878],\n",
      "        [ 0.28698409, -0.15106423, -0.05835875, -0.11543629]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.10862596, -0.04143320, -0.04955395, -0.23077297],\n",
      "        [ 0.19017221, -0.18716629, -0.07309996, -0.08664909]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.25506008, -0.14355098,  0.00202216, -0.19795503],\n",
      "        [ 0.39945284, -0.08777799,  0.08254255, -0.25164708]])\n",
      "---> Tensor(shape=[2, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[ 0.21955654, -0.03802521, -0.19999747, -0.28717789],\n",
      "        [ 0.30585366,  0.06244989, -0.08268742, -0.21563564]])\n",
      "global step 100, epoch: 1, batch: 100, loss: 1.30749, accu: 0.35500, speed: 4.52 step/s\n",
      "dev eval:\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--save_dir\", default='./checkpoint', type=str, help=\"The output directory where the model checkpoints will be written.\")\n",
    "parser.add_argument(\"--max_seq_length\", default=512, type=int, help=\"The maximum total input sequence length after tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, sequences shorter will be padded.\")\n",
    "parser.add_argument(\"--batch_size\", default=2, type=int, help=\"Batch size per GPU/CPU for training.\")\n",
    "parser.add_argument(\"--learning_rate\", default=2e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
    "parser.add_argument(\"--weight_decay\", default=0.0001, type=float, help=\"Weight decay if we apply some.\")\n",
    "parser.add_argument(\"--epochs\", default=10, type=int, help=\"Total number of training epochs to perform.\")\n",
    "parser.add_argument(\"--warmup_proportion\", default=0.1, type=float, help=\"Linear warmup proption over the training process.\")\n",
    "parser.add_argument(\"--init_from_ckpt\", type=str, default=None, help=\"The path of checkpoint to be loaded.\")\n",
    "parser.add_argument(\"--seed\", type=int, default=1000, help=\"random seed for initialization\")\n",
    "parser.add_argument('--device', choices=['cpu', 'gpu', 'xpu'], default=\"gpu\", help=\"Select which device to train model, defaults to gpu.\")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# ChineseBertModel\n",
    "CHINESEBERT_PADDLE_PATH = \"./pretrain_models/paddle/ChineseBERT-large\"\n",
    "model = ppnlp.transformers.GlyceBertForSequenceClassification.from_pretrained(CHINESEBERT_PADDLE_PATH, num_classes=4)\n",
    "\n",
    "# ChineseBertTokenizer\n",
    "tokenizer = ppnlp.transformers.ChineseBertTokenizer(CHINESEBERT_PADDLE_PATH)\n",
    "do_train(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a7bb4a-1b9e-4ffd-b475-90c0277b1065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
